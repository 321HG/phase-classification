{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cahya/.virtualenvs/phase/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import sys #only needed to determine Python version number\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "from scipy import signal\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import load_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.externals import joblib\n",
    "import xgboost as xgb\n",
    "import gcforest.gcforest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "from phase_utils import print_cm\n",
    "from phase_features_loader import PhaseFeaturesLoader\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "FEATURES_TINY = \"data/phase/ml_features_tiny.csv\"\n",
    "FEATURES = \"data/phase/ml_features.csv\"\n",
    "dataset_train = \"data/phase/ml_features_train.csv\"\n",
    "dataset_test = \"data/phase/ml_features_test.csv\"\n",
    "STA = \"URZ\"\n",
    "phases = [\"regP\", \"regS\", \"tele\", \"N\"]\n",
    "channels = [\"BHE\", \"BHZ\", \"BHN\"]\n",
    "classifiers = [\"Neural Network\", \"SVM\", \"XGBoost\", \"gcForest\"]\n",
    "validation_split = 0.1\n",
    "seed = 10\n",
    "file_stack1 = \"results/phase_stack_1.hdf5\"\n",
    "\n",
    "# parameters for NN:\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "dropout = 0.2\n",
    "layers = [32, 32]\n",
    "phase_length = {\"URZ\": {\"regP\": 6840, \"regS\": 6840, \"tele\": 6840, \"N\": 20520}}\n",
    "model_file_path_nn = \"results/phase_nn.hdf5\"\n",
    "verbose = 0\n",
    "cross_validation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n",
      "Pandas version 0.22.0\n",
      "Matplotlib version 2.1.2\n"
     ]
    }
   ],
   "source": [
    "print('Python version ' + sys.version)\n",
    "print('Pandas version ' + pd.__version__)\n",
    "print('Matplotlib version ' + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(model, x_test, y_test):\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    column_width = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * column_width\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(column_width) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(column_width) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(column_width) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack1_init(h5f, classifiers):\n",
    "    try:\n",
    "        dset_classifier = h5f['/classifier']\n",
    "    except KeyError:\n",
    "        dset_classifier = h5f.create_dataset(\"classifier\", data = [c.encode() for c in classifiers])\n",
    "        \n",
    "def stack1_save(h5f, arid, index, data):\n",
    "    dset_classifier = h5f['/classifier']\n",
    "    try:\n",
    "        dset_probability = h5f[\"/probability/{}\".format(arid)]\n",
    "    except KeyError:\n",
    "        dset_probability = h5f.create_dataset(\"/probability/{}\".format(arid), (len(dset_classifier), 4))\n",
    "    dset_probability[index] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify(y, n_classes=4):\n",
    "        'Returns labels in binary NumPy array'\n",
    "        return np.array([[1 if y[i] == j else 0 for j in range(n_classes)]\n",
    "                         for i in range(len(y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "       \n",
    "    @staticmethod\n",
    "    def create_model(layers, dropout=0.1):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(layers[0], input_shape=(1, 16), activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        for units in layers[1:]:\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        x_train = np.expand_dims(x_train, axis=1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
    "        y_train = sparsify(y_train)\n",
    "        y_train = np.expand_dims(y_train, axis=1)   \n",
    "        tensorboard = TensorBoard(log_dir='graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "        checkpoint = ModelCheckpoint(model_file_path_nn, monitor='acc', verbose=verbose,\n",
    "                                     save_best_only=True, mode='max')\n",
    "        self.model = NN.create_model(layers=layers, dropout=dropout)            \n",
    "        history = self.model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs, verbose=verbose,\n",
    "                  validation_split=0.1, callbacks=[checkpoint, tensorboard])\n",
    "\n",
    "        print(\"Max of acc: {}, val_acc: {}\".\n",
    "              format(max(history.history[\"acc\"]), max(history.history[\"val_acc\"])))\n",
    "        print(\"Min of loss: {}, val_loss: {}\".\n",
    "              format(min(history.history[\"loss\"]), min(history.history[\"val_loss\"])))\n",
    "    \n",
    "    def predict(self, x_test, y_test=None):\n",
    "        x_test = np.expand_dims(x_test, axis=1) \n",
    "        if y_test is not None:\n",
    "            y_test = sparsify(y_test)\n",
    "            y_test = np.expand_dims(y_test, axis=1) \n",
    "            score = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "            print(\"predict:\")\n",
    "            print(\"Accuracy: {}\".format(score[1]*100))\n",
    "        probability = self.model.predict(x_test, verbose=0)\n",
    "        return probability  \n",
    "        \n",
    "    def load(self, model_file_path):\n",
    "        self.model = load_model(model_file_path)\n",
    "        \n",
    "    def save(self, model_file_path):        \n",
    "        # save model to file\n",
    "        self.model.save(model_file_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "     \n",
    "    @staticmethod\n",
    "    def create_model():\n",
    "        params_grid = [\n",
    "            #{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "            #{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "            {'C': [1000], 'gamma': [0.001], 'kernel': ['rbf'], 'probability': [True]}\n",
    "        ]\n",
    "\n",
    "        model = GridSearchCV(svm.SVC(), params_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = SVM.create_model()\n",
    "        print(self.model)\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x_test, y_test=None):\n",
    "        probability = self.model.predict_proba(x_test)\n",
    "        if y_test is not None:\n",
    "            y_pred = self.model.predict(x_test)\n",
    "            prediction = [np.round(value) for value in y_pred]\n",
    "            accuracy = accuracy_score(y_test, prediction)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "        return probability\n",
    "        \n",
    "    def load(self, model_file_path):\n",
    "        self.model = joblib.load(model_file_path)\n",
    "        \n",
    "    def save(self, model_file_path):     \n",
    "        # save model to file\n",
    "        joblib.dump(self.model, model_file_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_model():\n",
    "        seed = 10\n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        # set xgboost params\n",
    "        params_grid = {\n",
    "            #'max_depth': [5, 6, 7, 8],\n",
    "            #'n_estimators': [i for i in range(88, 92, 1)],\n",
    "            #'learning_rate': np.linspace(0.1, 1, 20),\n",
    "            'max_depth': [6],\n",
    "            'n_estimators': [i for i in range(90, 91, 1)],\n",
    "            'learning_rate': np.linspace(0.1, 1, 2),\n",
    "        }\n",
    "\n",
    "        params_fixed = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'silent': 1,\n",
    "            'n_jobs': -1,\n",
    "            'verbose_eval': True\n",
    "        }\n",
    "\n",
    "        num_round = 30  # the number of training iterations\n",
    "\n",
    "        model = GridSearchCV(\n",
    "            estimator=xgb.XGBClassifier(**params_fixed, seed=seed),\n",
    "            param_grid=params_grid,\n",
    "            cv=cv,\n",
    "            scoring='accuracy'\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = XGBoost.create_model()\n",
    "        print(self.model)\n",
    "        sme = SMOTEENN(random_state=42)\n",
    "        x_train_res, y_train_res = sme.fit_sample(x_train, y_train)\n",
    "        self.model.fit(x_train_res, y_train_res)\n",
    "        \n",
    "    def predict(self, x_test, y_test=None):\n",
    "        probability = self.model.predict_proba(x_test)\n",
    "        if y_test is not None:\n",
    "            y_pred = self.model.predict(x_test)\n",
    "            prediction = [np.round(value) for value in y_pred]\n",
    "            # evaluate predictions\n",
    "            accuracy = accuracy_score(y_test, prediction)\n",
    "            print(\"Accuracy: {}\".format(accuracy * 100.0))\n",
    "        return probability\n",
    "        \n",
    "    def load(self, model_file_path):\n",
    "        self.model = joblib.load(model_file_path)\n",
    "        \n",
    "    def save(self, model_file_path):     \n",
    "        # save model to file\n",
    "        joblib.dump(self.model, model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCForest():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "     \n",
    "    @staticmethod\n",
    "    def create_model():\n",
    "        config = {\n",
    "              \"cascade\": {\n",
    "                  \"random_state\": 0,\n",
    "                  \"max_layers\": 100,\n",
    "                  \"early_stopping_rounds\": 3,\n",
    "                  \"n_classes\": 4,\n",
    "                  \"estimators\": [\n",
    "                      {\"n_folds\":5,\"type\":\"RandomForestClassifier\",\"n_estimators\":10,\"max_depth\":None,\"n_jobs\":-1},\n",
    "                      #{\"n_folds\":5,\"type\":\"XGBClassifier\",\"n_estimators\":10,\"max_depth\":5,\n",
    "                      #     \"objective\":\"multi:softprob\", \"silent\":True, \"nthread\":-1, \n",
    "                      #     \"learning_rate\":0.1},\n",
    "                      {\"n_folds\":5,\"type\":\"ExtraTreesClassifier\",\"n_estimators\":10,\"max_depth\":None,\"n_jobs\":-1},\n",
    "                      {\"n_folds\":5,\"type\":\"LogisticRegression\"}\n",
    "                  ]\n",
    "              }\n",
    "            }\n",
    "\n",
    "        model = gcforest.gcforest.GCForest(config)\n",
    "        return model\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = GCForest.create_model()\n",
    "        print(self.model)\n",
    "        self.model.fit_transform(x_train, y_train)        \n",
    "        \n",
    "    def predict(self, x_test, y_test=None):\n",
    "        probability = self.model.predict_proba(x_test)\n",
    "        if y_test is not None:\n",
    "            y_pred = self.model.predict(x_test)\n",
    "            prediction = [np.round(value) for value in y_pred]\n",
    "            accuracy = accuracy_score(y_test, prediction)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "        return probability\n",
    "        \n",
    "    def load(self, model_file_path):\n",
    "        self.model = joblib.load(model_file_path)\n",
    "        \n",
    "    def save(self, model_file_path):     \n",
    "        # save model to file\n",
    "        joblib.dump(self.model, model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stack1 file \n",
    "h5f = h5py.File(file_stack1, \"w\")\n",
    "stack1_init(h5f, classifiers)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length regP:6840\n",
      "length regS:6840\n",
      "length tele:6840\n",
      "length N:20520\n"
     ]
    }
   ],
   "source": [
    "# load train dataset\n",
    "pd_train = PhaseFeaturesLoader(filename=dataset_train, validation_split=validation_split,\n",
    "                         phase_length=phase_length, batch_size=batch_size)\n",
    "\n",
    "x_train, y_train = pd_train.get_dataset(expand_dim=False, y_onehot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length regP:2280\n",
      "length regS:2280\n",
      "length tele:2280\n",
      "length N:6840\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# load test dataset\n",
    "pd_test = PhaseFeaturesLoader(filename=dataset_test, phase_length=phase_length, batch_size=batch_size)\n",
    "x_test, y_test = pd_test.get_dataset(expand_dim=False, y_onehot=False)\n",
    "print(pd_test.get_phase_index(100089180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41040, 16)\n",
      "(13680, 16)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XGBoost': <class '__main__.XGBoost'>, 'NN': <class '__main__.NN'>, 'SVM': <class '__main__.SVM'>, 'GCForest': <class '__main__.GCForest'>}\n",
      "{'XGBoost': 2, 'NN': 0, 'SVM': 1, 'GCForest': 3}\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\"NN\", \"SVM\", \"XGBoost\", \"GCForest\"]\n",
    "classifier_index = {classifier: i for i, classifier in enumerate(classifiers)}\n",
    "functions = globals().copy()\n",
    "classifier_class = {c: functions.get(c) for c in classifiers}\n",
    "print(classifier_class)\n",
    "print(classifier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "arids = pd_test.get_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max of acc: 0.6556746805672111, val_acc: 0.699317738791423\n",
      "Min of loss: 0.812684848914292, val_loss: 0.7458223198589525\n",
      "predict:\n",
      "Accuracy: 70.05116959064327\n",
      "arid: 69604157, proba: [[0.6791008  0.00223833 0.2684865  0.0501744 ]], y: 0\n",
      "arid: 61608769, proba: [[0.02106345 0.19713983 0.07202364 0.70977306]], y: 1\n",
      "arid: 35743138, proba: [[0.03073326 0.05043396 0.05203848 0.8667943 ]], y: 3\n",
      "arid: 84668653, proba: [[0.71791524 0.00149557 0.2288035  0.05178571]], y: 0\n",
      "arid: 99582459, proba: [[0.41767588 0.00899581 0.27152824 0.30180007]], y: 3\n",
      "arid: 15301629, proba: [[0.0182363  0.39722526 0.09704833 0.48749018]], y: 3\n",
      "arid: 28075686, proba: [[0.01663931 0.5210031  0.10620998 0.3561475 ]], y: 3\n",
      "arid: 81864273, proba: [[0.02709439 0.57804734 0.18832013 0.20653816]], y: 1\n",
      "arid: 121436627, proba: [[0.01523543 0.01778264 0.02845851 0.93852335]], y: 3\n",
      "arid: 60381321, proba: [[0.06511082 0.33958364 0.0727029  0.5226026 ]], y: 2\n",
      "arid: 47370982, proba: [[0.01022348 0.54931104 0.09300622 0.34745923]], y: 1\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid=[{'C': [1000], 'probability': [True], 'gamma': [0.001], 'kernel': ['rbf']}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=0)\n",
      "Accuracy: 73.87%\n",
      "arid: 69604157, proba: [8.64235199e-01 4.07119685e-04 1.18094969e-01 1.72627124e-02], y: 0\n",
      "arid: 61608769, proba: [0.00643377 0.26442466 0.07793592 0.65120565], y: 1\n",
      "arid: 35743138, proba: [0.03736924 0.05268213 0.09412865 0.81581998], y: 3\n",
      "arid: 84668653, proba: [9.33387327e-01 2.76871090e-04 5.25696227e-02 1.37661794e-02], y: 0\n",
      "arid: 99582459, proba: [0.28564756 0.00572069 0.1460498  0.56258195], y: 3\n",
      "arid: 15301629, proba: [0.00655004 0.28894528 0.07471983 0.62978485], y: 3\n",
      "arid: 28075686, proba: [0.00934309 0.54658236 0.11981797 0.32425658], y: 3\n",
      "arid: 81864273, proba: [0.01059079 0.67057337 0.17075723 0.14807861], y: 1\n",
      "arid: 121436627, proba: [0.0056999  0.0264633  0.00766412 0.96017268], y: 3\n",
      "arid: 60381321, proba: [0.04662372 0.63766472 0.05577844 0.25993313], y: 2\n",
      "arid: 47370982, proba: [0.00463143 0.77929517 0.08437273 0.13170068], y: 1\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=10, shuffle=True),\n",
      "       error_score='raise',\n",
      "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=10, silent=1,\n",
      "       subsample=1, verbose_eval=True),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [90], 'learning_rate': array([0.1, 1. ]), 'max_depth': [6]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='accuracy', verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-03-28 20:07:41,168][cascade_classifier.fit_transform] X_groups_train.shape=[(41040, 16)],y_train.shape=(41040,),X_groups_test.shape=no_test,y_test.shape=no_test\n",
      "[ 2018-03-28 20:07:41,169][cascade_classifier.fit_transform] group_dims=[16]\n",
      "[ 2018-03-28 20:07:41,170][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-03-28 20:07:41,170][cascade_classifier.fit_transform] group_ends=[16]\n",
      "[ 2018-03-28 20:07:41,171][cascade_classifier.fit_transform] X_train.shape=(41040, 16),X_test.shape=(0, 16)\n",
      "[ 2018-03-28 20:07:41,173][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(41040, 16), X_cur_test.shape=(0, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.64619883040936\n",
      "arid: 69604157, proba: [9.9727947e-01 5.1334776e-08 2.7149587e-03 5.5050232e-06], y: 0\n",
      "arid: 61608769, proba: [7.7785910e-05 8.9660579e-01 5.0218686e-02 5.3097706e-02], y: 1\n",
      "arid: 35743138, proba: [5.6787278e-04 8.2083084e-03 7.3777507e-03 9.8384607e-01], y: 3\n",
      "arid: 84668653, proba: [9.9948138e-01 4.8130399e-08 5.1849242e-04 1.3714946e-07], y: 0\n",
      "arid: 99582459, proba: [9.9042106e-01 1.6049256e-05 7.7369376e-03 1.8259495e-03], y: 3\n",
      "arid: 15301629, proba: [4.5310586e-05 9.7115821e-01 1.6710233e-02 1.2086293e-02], y: 3\n",
      "arid: 28075686, proba: [8.3121187e-05 7.7143037e-01 2.1689783e-01 1.1588650e-02], y: 3\n",
      "arid: 81864273, proba: [3.9291240e-07 1.3285497e-01 8.6706066e-01 8.3938903e-05], y: 1\n",
      "arid: 121436627, proba: [2.0858168e-05 3.0490404e-05 2.1999513e-04 9.9972862e-01], y: 3\n",
      "arid: 60381321, proba: [1.9034736e-02 9.5777225e-01 2.3109468e-02 8.3532796e-05], y: 2\n",
      "arid: 47370982, proba: [1.2950872e-07 9.9619019e-01 3.8040639e-03 5.6259655e-06], y: 1\n",
      "<gcforest.gcforest.GCForest object at 0x7f276761b278>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-03-28 20:07:41,530][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=73.84%\n",
      "[ 2018-03-28 20:07:41,853][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=74.13%\n",
      "[ 2018-03-28 20:07:42,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=73.93%\n",
      "[ 2018-03-28 20:07:42,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=74.63%\n",
      "[ 2018-03-28 20:07:42,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=74.43%\n",
      "[ 2018-03-28 20:07:42,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=74.19%\n",
      "[ 2018-03-28 20:07:43,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_0.predict)=74.29%\n",
      "[ 2018-03-28 20:07:43,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_1.predict)=74.63%\n",
      "[ 2018-03-28 20:07:43,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_2.predict)=73.05%\n",
      "[ 2018-03-28 20:07:43,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_3.predict)=73.51%\n",
      "[ 2018-03-28 20:07:43,929][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_4.predict)=73.95%\n",
      "[ 2018-03-28 20:07:43,932][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 5_folds.train_cv.predict)=73.89%\n",
      "[ 2018-03-28 20:07:45,687][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_0.predict)=66.95%\n",
      "[ 2018-03-28 20:07:47,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_1.predict)=67.36%\n",
      "[ 2018-03-28 20:07:49,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_2.predict)=68.37%\n",
      "[ 2018-03-28 20:07:50,867][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_3.predict)=67.04%\n",
      "[ 2018-03-28 20:07:52,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_4.predict)=67.20%\n",
      "[ 2018-03-28 20:07:52,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 5_folds.train_cv.predict)=67.39%\n",
      "[ 2018-03-28 20:07:52,530][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=75.33%\n",
      "[ 2018-03-28 20:07:52,533][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(41040, 28), X_cur_test.shape=(0, 28)\n",
      "[ 2018-03-28 20:07:52,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=74.34%\n",
      "[ 2018-03-28 20:07:53,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=74.12%\n",
      "[ 2018-03-28 20:07:53,510][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=75.43%\n",
      "[ 2018-03-28 20:07:53,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=73.96%\n",
      "[ 2018-03-28 20:07:54,158][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=74.60%\n",
      "[ 2018-03-28 20:07:54,161][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=74.49%\n",
      "[ 2018-03-28 20:07:54,395][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_0.predict)=74.06%\n",
      "[ 2018-03-28 20:07:54,617][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_1.predict)=74.95%\n",
      "[ 2018-03-28 20:07:54,839][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_2.predict)=73.53%\n",
      "[ 2018-03-28 20:07:55,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_3.predict)=74.67%\n",
      "[ 2018-03-28 20:07:55,284][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_4.predict)=74.57%\n",
      "[ 2018-03-28 20:07:55,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 5_folds.train_cv.predict)=74.36%\n",
      "[ 2018-03-28 20:07:57,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_0.predict)=76.00%\n",
      "[ 2018-03-28 20:07:59,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_1.predict)=76.30%\n",
      "[ 2018-03-28 20:08:02,561][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_2.predict)=75.58%\n",
      "[ 2018-03-28 20:08:04,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_3.predict)=75.19%\n",
      "[ 2018-03-28 20:08:07,424][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_4.predict)=75.84%\n",
      "[ 2018-03-28 20:08:07,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 5_folds.train_cv.predict)=75.78%\n",
      "[ 2018-03-28 20:08:07,428][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=76.29%\n",
      "[ 2018-03-28 20:08:07,431][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(41040, 28), X_cur_test.shape=(0, 28)\n",
      "[ 2018-03-28 20:08:07,861][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=74.35%\n",
      "[ 2018-03-28 20:08:08,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=73.81%\n",
      "[ 2018-03-28 20:08:08,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=74.54%\n",
      "[ 2018-03-28 20:08:08,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=74.26%\n",
      "[ 2018-03-28 20:08:09,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=73.72%\n",
      "[ 2018-03-28 20:08:09,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=74.13%\n",
      "[ 2018-03-28 20:08:09,391][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_0.predict)=74.71%\n",
      "[ 2018-03-28 20:08:09,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_1.predict)=74.05%\n",
      "[ 2018-03-28 20:08:09,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_2.predict)=74.21%\n",
      "[ 2018-03-28 20:08:10,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_3.predict)=73.48%\n",
      "[ 2018-03-28 20:08:10,278][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_4.predict)=73.38%\n",
      "[ 2018-03-28 20:08:10,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 5_folds.train_cv.predict)=73.96%\n",
      "[ 2018-03-28 20:08:12,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_0.predict)=75.76%\n",
      "[ 2018-03-28 20:08:14,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_1.predict)=76.17%\n",
      "[ 2018-03-28 20:08:16,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_2.predict)=76.27%\n",
      "[ 2018-03-28 20:08:19,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_3.predict)=76.95%\n",
      "[ 2018-03-28 20:08:21,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_4.predict)=75.45%\n",
      "[ 2018-03-28 20:08:21,185][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 5_folds.train_cv.predict)=76.12%\n",
      "[ 2018-03-28 20:08:21,187][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=75.99%\n",
      "[ 2018-03-28 20:08:21,190][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(41040, 28), X_cur_test.shape=(0, 28)\n",
      "[ 2018-03-28 20:08:21,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_0.predict)=74.70%\n",
      "[ 2018-03-28 20:08:21,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_1.predict)=74.09%\n",
      "[ 2018-03-28 20:08:22,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_2.predict)=75.48%\n",
      "[ 2018-03-28 20:08:22,494][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_3.predict)=74.67%\n",
      "[ 2018-03-28 20:08:22,816][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_4.predict)=74.78%\n",
      "[ 2018-03-28 20:08:22,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_cv.predict)=74.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-03-28 20:08:23,053][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_0.predict)=74.91%\n",
      "[ 2018-03-28 20:08:23,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_1.predict)=73.56%\n",
      "[ 2018-03-28 20:08:23,497][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_2.predict)=74.35%\n",
      "[ 2018-03-28 20:08:23,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_3.predict)=75.04%\n",
      "[ 2018-03-28 20:08:23,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_4.predict)=73.96%\n",
      "[ 2018-03-28 20:08:23,943][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 5_folds.train_cv.predict)=74.37%\n",
      "[ 2018-03-28 20:08:26,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_0.predict)=76.52%\n",
      "[ 2018-03-28 20:08:28,062][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_1.predict)=75.26%\n",
      "[ 2018-03-28 20:08:30,032][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_2.predict)=76.44%\n",
      "[ 2018-03-28 20:08:31,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_3.predict)=75.38%\n",
      "[ 2018-03-28 20:08:33,931][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_4.predict)=76.12%\n",
      "[ 2018-03-28 20:08:33,933][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 5_folds.train_cv.predict)=75.94%\n",
      "[ 2018-03-28 20:08:33,935][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=76.13%\n",
      "[ 2018-03-28 20:08:33,937][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(41040, 28), X_cur_test.shape=(0, 28)\n",
      "[ 2018-03-28 20:08:34,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_0.predict)=74.09%\n",
      "[ 2018-03-28 20:08:34,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_1.predict)=73.36%\n",
      "[ 2018-03-28 20:08:34,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_2.predict)=74.82%\n",
      "[ 2018-03-28 20:08:35,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_3.predict)=74.33%\n",
      "[ 2018-03-28 20:08:35,560][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_4.predict)=74.63%\n",
      "[ 2018-03-28 20:08:35,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_cv.predict)=74.24%\n",
      "[ 2018-03-28 20:08:35,796][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_0.predict)=74.43%\n",
      "[ 2018-03-28 20:08:36,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_1.predict)=74.33%\n",
      "[ 2018-03-28 20:08:36,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_2.predict)=74.28%\n",
      "[ 2018-03-28 20:08:36,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_3.predict)=74.90%\n",
      "[ 2018-03-28 20:08:36,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_4.predict)=73.94%\n",
      "[ 2018-03-28 20:08:36,687][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 5_folds.train_cv.predict)=74.38%\n",
      "[ 2018-03-28 20:08:38,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_0.predict)=75.23%\n",
      "[ 2018-03-28 20:08:40,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_1.predict)=76.67%\n",
      "[ 2018-03-28 20:08:42,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_2.predict)=75.26%\n",
      "[ 2018-03-28 20:08:44,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_3.predict)=76.01%\n",
      "[ 2018-03-28 20:08:46,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_4.predict)=76.89%\n",
      "[ 2018-03-28 20:08:46,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 5_folds.train_cv.predict)=76.01%\n",
      "[ 2018-03-28 20:08:46,978][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=76.05%\n",
      "[ 2018-03-28 20:08:46,979][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=76.29%, accuracy_test=0.00%\n",
      "[ 2018-03-28 20:08:47,187][cascade_classifier.transform] X_groups_test.shape=[(13680, 16)]\n",
      "[ 2018-03-28 20:08:47,188][cascade_classifier.transform] group_dims=[16]\n",
      "[ 2018-03-28 20:08:47,188][cascade_classifier.transform] X_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:08:47,189][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:08:48,235][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(13680, 28)\n",
      "[ 2018-03-28 20:08:49,284][cascade_classifier.transform] X_groups_test.shape=[(13680, 16)]\n",
      "[ 2018-03-28 20:08:49,285][cascade_classifier.transform] group_dims=[16]\n",
      "[ 2018-03-28 20:08:49,286][cascade_classifier.transform] X_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:08:49,287][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:08:50,331][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(13680, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.19%\n",
      "arid: 69604157, proba: [7.4090809e-01 3.4841083e-04 1.7340475e-01 8.5338831e-02], y: 0\n",
      "arid: 61608769, proba: [0.00152014 0.37141058 0.08975059 0.5373187 ], y: 1\n",
      "arid: 35743138, proba: [0.01188111 0.02203865 0.04967971 0.9164005 ], y: 3\n",
      "arid: 84668653, proba: [8.9830559e-01 2.6878130e-04 7.4064136e-02 2.7361521e-02], y: 0\n",
      "arid: 99582459, proba: [0.17047971 0.00154391 0.08510912 0.74286723], y: 3\n",
      "arid: 15301629, proba: [0.00201666 0.42962763 0.1686209  0.39973482], y: 3\n",
      "arid: 28075686, proba: [0.00193531 0.57114047 0.2833099  0.14361435], y: 3\n",
      "arid: 81864273, proba: [0.00122345 0.5824758  0.24257678 0.173724  ], y: 1\n",
      "arid: 121436627, proba: [0.00497894 0.01688245 0.00762629 0.97051233], y: 3\n",
      "arid: 60381321, proba: [0.02419232 0.50248176 0.1295938  0.34373203], y: 2\n",
      "arid: 47370982, proba: [4.0298238e-04 7.6103991e-01 9.6017897e-02 1.4253926e-01], y: 1\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    model = classifier_class[classifier]()\n",
    "    model.fit(x_train, y_train)\n",
    "    model.save(\"results/phase_train_{}.mdl\".format(classifier.lower()))\n",
    "    probability = model.predict(x_test, y_test)\n",
    "    for i, arid in enumerate(arids):\n",
    "        print(\"arid: {}, proba: {}, y: {}\".format(arid, probability[i], y_test[i]))\n",
    "        if i >= 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict:\n",
      "Accuracy: 70.05116959064327\n",
      "Accuracy: 73.87%\n",
      "Accuracy: 72.64619883040936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-03-28 20:31:33,651][cascade_classifier.transform] X_groups_test.shape=[(13680, 16)]\n",
      "[ 2018-03-28 20:31:33,652][cascade_classifier.transform] group_dims=[16]\n",
      "[ 2018-03-28 20:31:33,653][cascade_classifier.transform] X_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:31:33,654][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:31:34,699][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(13680, 28)\n",
      "[ 2018-03-28 20:31:35,749][cascade_classifier.transform] X_groups_test.shape=[(13680, 16)]\n",
      "[ 2018-03-28 20:31:35,750][cascade_classifier.transform] group_dims=[16]\n",
      "[ 2018-03-28 20:31:35,751][cascade_classifier.transform] X_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:31:35,751][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(13680, 16)\n",
      "[ 2018-03-28 20:31:36,796][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(13680, 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.19%\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File(file_stack1, \"r+\")\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    model = classifier_class[classifier]()\n",
    "    model.load(\"results/phase_train_{}.mdl\".format(classifier.lower()))\n",
    "    probability = model.predict(x_test, y_test)\n",
    "    for j, arid in enumerate(arids):\n",
    "        stack1_save(h5f, arid, i, probability[j, :])\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
